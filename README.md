# Crawleando dados da internet
Neste repositorio veremos uma aplicação crawleando um site da internet, onde criamos um DataFrame e subimos para um Banco de dados SQL Server na AWS. 
Recuperamos os dados da AWS e plotamos um grafico. 

# Libs utilizadas
* Pandas: pip install pandas
* Pyodbc: sudo pip install pyodbc
* Sqlalcjemy: sudo pip install sqlalchemy
* S3fs: sudo pip install s3fs
* Boto3: pip install boto3
* Selenium: pip install selenium
* Requests: pip install requests
* BeautifulSoup: pip install BeautifulSoup
* Plotly: pip install plotly
